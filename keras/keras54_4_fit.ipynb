{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 160 images belonging to 2 classes.\n",
      "Found 120 images belonging to 2 classes.\n",
      "2\n",
      "(160, 100, 100, 1)\n",
      "(160,)\n",
      "<class 'keras.preprocessing.image.DirectoryIterator'>\n",
      "<class 'tuple'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_data_Gen = ImageDataGenerator (\n",
    "    rescale = 1./255, \n",
    "    horizontal_flip = True,         # 수평선을 기준으로 반전\n",
    "    vertical_flip = True,           # 수직선을 기준으로 반전\n",
    "    width_shift_range = 0.1,        # 10% 만큼 가로 이동\n",
    "    height_shift_range = 0.1,       # 10% 만큼 세로 이동\n",
    "    rotation_range = 5,             # 회전\n",
    "    zoom_range = 0.7,               # 확대\n",
    "    shear_range = 0.7,              # 엇갈림\n",
    "    fill_mode = 'nearest'           # 축 이동을 했을 때 비는 부분을 가까운 값으로 채운다.\n",
    ")\n",
    "\n",
    "test_data_Gen = ImageDataGenerator (\n",
    "    rescale = 1./255                # 테스트 데이터는 리스케일링만 한다.: 평가에 쓰이는 테스트 데이터는 증폭시키지 않은 원 데이터 사용\n",
    ")\n",
    "\n",
    "xy_train = train_data_Gen.flow_from_directory (\n",
    "    'C:/study/keras/keras_data/brain/train',\n",
    "    target_size=(100,100),\n",
    "    batch_size= 1024,                  # 10개씩 자르므로 16번 돈다.\n",
    "    class_mode='binary',\n",
    "    color_mode='grayscale',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# ad(alzheimer disease) = 0, normal = 1  \n",
    "# x = (160, 150, 150, 1), y = (160,) → 흑백 image \n",
    "# 160장 중에 ad, normal 각 80장씩\n",
    "# np.unique = 0, 1\n",
    "\n",
    "xy_test = train_data_Gen.flow_from_directory (\n",
    "    'C:/study/keras/keras_data/brain/test',\n",
    "    target_size=(100,100),\n",
    "    batch_size=1024,                  # 10개씩 자르므로 16번 돈다.\n",
    "    class_mode='binary',\n",
    "    color_mode='grayscale',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# print(xy_train, '\\n', xy_test)    # <keras.preprocessing.image.DirectoryIterator object at 0x000002862718CAC0> \n",
    "# print(xy_train[0])                # x data와 y data 개수, y data 개수 = batch_size 개수 만큼\n",
    "# print(xy_train[0][0])\n",
    "# print(xy_train[0][1])\n",
    "print(len(xy_train[0]))  \n",
    "print(xy_train[0][0].shape)         # x (10 = batch_size)\n",
    "print(xy_train[0][1].shape)         # y\n",
    "\n",
    "# batch_size를 전체 데이터보다 최대한 크게 끔 지정하면 전체 데이터의 개수를 알 수 있다.\n",
    "print(type(xy_train)) \n",
    "print(type(xy_train[0]))             # 튜플은 변경 불가\n",
    "print(type(xy_train[0][0]))          # x\n",
    "print(type(xy_train[0][1]))          # y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, (2,2), input_shape=(100, 100, 1), activation='relu'))\n",
    "model.add(Conv2D(64, (2,2), activation='relu'))\n",
    "model.add(Conv2D(64, (2,2), activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 컴파일, 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bitcamp\\AppData\\Local\\Temp\\ipykernel_5736\\1532313118.py:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  hist = model.fit_generator(xy_train, steps_per_epoch=16, epochs=128, validation_data=xy_test, validation_steps=4)  # steps_per_epoch: 1 에포크 당 배치 사이즈에 따른 훈련 횟수\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/128\n",
      " 1/16 [>.............................] - ETA: 48s - loss: 0.6930 - acc: 0.4938WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2048 batches). You may need to use the repeat() function when building your dataset.\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 4 batches). You may need to use the repeat() function when building your dataset.\n",
      "16/16 [==============================] - 5s 87ms/step - loss: 0.6930 - acc: 0.4938 - val_loss: 1.0385 - val_acc: 0.5000\n",
      "acc:  0.4937500059604645\n",
      "loss:  0.6930215358734131\n",
      "val_acc:  0.5\n",
      "val_loss:  1.0385197401046753\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics='acc')\n",
    "# hist = model.fit_generator(xy_train, steps_per_epoch=16, epochs=128, validation_data=xy_test, validation_steps=4)  # steps_per_epoch: 1 에포크 당 배치 사이즈에 따른 훈련 횟수\n",
    "hist = model.fit(xy_train, epochs=128, batch_size=10, validation_data=(xy_test[0][0], xy_test[0][1]))  # steps_per_epoch: 1 에포크 당 배치 사이즈에 따른 훈련 횟수\n",
    "\n",
    "acc = hist.history['acc']\n",
    "val_acc = hist.history['val_acc']\n",
    "loss = hist.history['loss']\n",
    "val_loss = hist.history['val_loss']\n",
    "print('acc: ', acc[-1])\n",
    "print('loss: ', loss[-1])\n",
    "print('val_acc: ', val_acc[-1])\n",
    "print('val_loss: ', val_loss[-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf274gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "10848e9bd3f5e7d93542d388001135334854454e7336dcf54c4ef52885ee0fb0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
