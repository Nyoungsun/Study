{"cells":[{"cell_type":"markdown","metadata":{"id":"-N8QRhtyF-u4"},"source":["# 1. 데이터"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1674922564717,"user":{"displayName":"노영선(과학기술대학 컴퓨터정보통신공학부)","userId":"09542015644926611058"},"user_tz":-540},"id":"zTSuXZ9bFvXz","outputId":"2175545f-e39e-441c-f785-bc1c392c4c64"},"outputs":[{"name":"stdout","output_type":"stream","text":["(1383, 5, 5) (593, 5, 5)\n","(1383, 1) (593, 1)\n","(1383, 5, 5) (593, 5, 5)\n"]}],"source":["import numpy as np\n","import pandas as pd\n","from sklearn. preprocessing import MinMaxScaler\n","from sklearn.model_selection import train_test_split\n","\n","# PATH = '/content/drive/MyDrive/'\n","PATH = 'C:/study/keras/keras_data/stock/'\n","\n","samsung = pd.read_csv(PATH + '삼성전자 주가.csv', header=0, index_col=None, sep=',', encoding='cp949', thousands=',').loc[::-1]\n","# print(samsung)\n","# print(samsung.shape) #(1980, 17)\n","\n","amore = pd.read_csv(PATH + '아모레퍼시픽 주가.csv', header=0, index_col=None, sep=',', encoding='cp949', thousands=',').loc[::-1]\n","# print(amore)\n","# print(amore.shape)   #(2220, 17)\n","\n","# 삼성전자 x ,y 추출\n","samsung_x = samsung[['고가', '저가','종가', '외인(수량)', '기관']]\n","samsung_y = samsung[['시가']].to_numpy() # x 데이터는 아래에서 split 함수를 거치며 numpy array로 변환되므로 y는 여기서 변환해준다\n","# print(samsung_x)\n","# print(samsung_y)\n","# print(samsung_x.shape) # (1980, 5)\n","# print(samsung_y.shape) # (1980, 1)\n","\n","# 아모레 x, y 추출\n","amore_x = amore.loc[1979:0,['고가', '저가', '종가', '외인(수량)', '시가']]\n","# print(amore_x)\n","# print(amore_x.shape) #(1980, 5)\n","\n","samsung_x = MinMaxScaler().fit_transform(samsung_x)\n","amore_x = MinMaxScaler().fit_transform(amore_x)\n","\n","def split_data(dataset, timesteps):\n","    tmp = []\n","    for i in range(len(dataset) - timesteps + 1):\n","        subset = dataset[i : (i + timesteps)]\n","        tmp.append(subset)\n","    return np.array(tmp)\n","\n","samsung_x = split_data(samsung_x, 5)\n","amore_x = split_data(amore_x, 5)\n","# print(samsung_x.shape) #(1976, 5, 5)\n","# print(amore_x.shape) #(1976, 5, 5)\n","\n","samsung_y = samsung_y[4:, :] # x 데이터와 shape을 맞춰주기 위해 4개 행 제거\n","# print(samsung_y.shape) #(1976, 1)\n","\n","# 예측에 사용할 데이터 추출 (마지막 값)\n","samsung_x_predict = samsung_x[-1].reshape(-1, 5, 5)\n","amore_x_predict = amore_x[-1].reshape(-1, 5, 5)\n","# print(samsung_x_predict.shape) # (5, 5, 1)\n","# print(amore_x_predict.shape) # (5, 5, 1)\n","\n","samsung_x_train, samsung_x_test, samsung_y_train, samsung_y_test, amore_x_train, amore_x_test  = train_test_split(\n","    samsung_x, samsung_y, amore_x, train_size=0.7, random_state=333)\n","\n","print(samsung_x_train.shape, samsung_x_test.shape)  # (1383, 5, 5) (593, 5, 5)\n","print(samsung_y_train.shape, samsung_y_test.shape) # (1383, 1) (593, 1)\n","print(amore_x_train.shape, amore_x_test.shape)  # (1383, 5, 5) (593, 5, 5)"]},{"cell_type":"markdown","metadata":{"id":"QStlUZ62GIzR"},"source":["# 2. 모델"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":641,"status":"ok","timestamp":1674922565344,"user":{"displayName":"노영선(과학기술대학 컴퓨터정보통신공학부)","userId":"09542015644926611058"},"user_tz":-540},"id":"Bxhe-GAGD1cx","outputId":"042ec8bb-2aab-4be6-ec6b-1394012354cb"},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_1 (InputLayer)           [(None, 5, 5)]       0           []                               \n","                                                                                                  \n"," lstm (LSTM)                    (None, 5, 64)        17920       ['input_1[0][0]']                \n","                                                                                                  \n"," dropout (Dropout)              (None, 5, 64)        0           ['lstm[0][0]']                   \n","                                                                                                  \n"," lstm_1 (LSTM)                  (None, 128)          98816       ['dropout[0][0]']                \n","                                                                                                  \n"," dense (Dense)                  (None, 256)          33024       ['lstm_1[0][0]']                 \n","                                                                                                  \n"," dropout_1 (Dropout)            (None, 256)          0           ['dense[0][0]']                  \n","                                                                                                  \n"," dense_1 (Dense)                (None, 1024)         263168      ['dropout_1[0][0]']              \n","                                                                                                  \n"," dense_2 (Dense)                (None, 128)          131200      ['dense_1[0][0]']                \n","                                                                                                  \n"," dropout_2 (Dropout)            (None, 128)          0           ['dense_2[0][0]']                \n","                                                                                                  \n"," dropout_5 (Dropout)            (None, 128)          0           ['dropout_2[0][0]']              \n","                                                                                                  \n"," dense_3 (Dense)                (None, 32)           4128        ['dropout_2[0][0]']              \n","                                                                                                  \n"," dense_8 (Dense)                (None, 32)           4128        ['dropout_5[0][0]']              \n","                                                                                                  \n"," dense_4 (Dense)                (None, 1)            33          ['dense_3[0][0]']                \n","                                                                                                  \n"," dense_9 (Dense)                (None, 1)            33          ['dense_8[0][0]']                \n","                                                                                                  \n"," concatenate (Concatenate)      (None, 2)            0           ['dense_4[0][0]',                \n","                                                                  'dense_9[0][0]']                \n","                                                                                                  \n"," dense_10 (Dense)               (None, 64)           192         ['concatenate[0][0]']            \n","                                                                                                  \n"," dense_11 (Dense)               (None, 128)          8320        ['dense_10[0][0]']               \n","                                                                                                  \n"," dense_12 (Dense)               (None, 256)          33024       ['dense_11[0][0]']               \n","                                                                                                  \n"," dense_13 (Dense)               (None, 512)          131584      ['dense_12[0][0]']               \n","                                                                                                  \n"," dense_14 (Dense)               (None, 32)           16416       ['dense_13[0][0]']               \n","                                                                                                  \n"," input_2 (InputLayer)           [(None, 5, 5)]       0           []                               \n","                                                                                                  \n"," dense_15 (Dense)               (None, 1)            33          ['dense_14[0][0]']               \n","                                                                                                  \n","==================================================================================================\n","Total params: 742,019\n","Trainable params: 742,019\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}],"source":["\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Dense, Dropout, Input, LSTM, concatenate\n","\n","# 삼성전자\n","samsung_input = Input(shape=(5, 5))\n","samsung_layer1 = LSTM(64, return_sequences=True, activation='relu')(samsung_input)\n","samsung_layer1 = Dropout(0.2)(samsung_layer1)\n","samsung_layer2 = LSTM(128, activation='relu')(samsung_layer1)\n","samsung_layer3 = Dense(256, activation='relu')(samsung_layer2)\n","samsung_layer4 = Dropout(0.2)(samsung_layer3)\n","samsung_layer5 = Dense(1024, activation='relu')(samsung_layer4)\n","samsung_layer6 = Dense(128, activation='relu')(samsung_layer5)\n","samsung_layer6 = Dropout(0.2)(samsung_layer6)\n","samsung_layer7 = Dense(32, activation='relu')(samsung_layer6)\n","samsung_output = Dense(1)(samsung_layer7)\n","\n","# 아모레퍼시픽\n","amore_input = Input(shape=(5, 5))\n","amore_layer1 = LSTM(64, return_sequences=True, activation='relu')(amore_input)\n","amore_layer1 = Dropout(0.2)(amore_layer1)\n","amore_layer2 = LSTM(128, activation='relu')(amore_layer1)\n","amore_layer3 = Dense(256, activation='relu')(amore_layer2)\n","amore_layer4 = Dropout(0.2)(amore_layer3)\n","amore_layer5 = Dense(1024, activation='relu')(amore_layer4)\n","amore_layer6 = Dense(128, activation='relu')(amore_layer5)\n","amore_layer6 = Dropout(0.2)(samsung_layer6)\n","amore_layer7 = Dense(32, activation='relu')(amore_layer6)\n","amore_output = Dense(1)(amore_layer7)\n","\n","# 병합\n","merge_layer1 = concatenate([samsung_output, amore_output])\n","merge_layer2 = Dense(64, activation='relu')(merge_layer1)\n","merge_layer3 = Dense(128, activation='relu')(merge_layer2)\n","merge_layer4 = Dense(256, activation='relu')(merge_layer3)\n","merge_layer5 = Dense(512, activation='relu')(merge_layer4)\n","merge_layer6 = Dense(32, activation='relu')(merge_layer5)\n","merge_output = Dense(1, activation='relu')(merge_layer6)\n","\n","model = Model(inputs=[samsung_input, amore_input], outputs=[merge_output])\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"bzlHgKYPGcYU"},"source":["# 3. 컴파일, 훈련\n","\n"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":52937,"status":"ok","timestamp":1674922618263,"user":{"displayName":"노영선(과학기술대학 컴퓨터정보통신공학부)","userId":"09542015644926611058"},"user_tz":-540},"id":"enZqANa9Gal1","outputId":"af6c4ae2-b67e-42f1-9fd6-969711cf4862"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/1024\n","2/2 [==============================] - 3s 436ms/step - loss: 1419245125632.0000 - val_loss: 1492798537728.0000\n","Epoch 2/1024\n","2/2 [==============================] - 0s 146ms/step - loss: 1419245256704.0000 - val_loss: 1492798275584.0000\n","Epoch 3/1024\n","2/2 [==============================] - 0s 144ms/step - loss: 1419244863488.0000 - val_loss: 1492797751296.0000\n","Epoch 4/1024\n","2/2 [==============================] - 0s 142ms/step - loss: 1419244339200.0000 - val_loss: 1492796178432.0000\n","Epoch 5/1024\n","2/2 [==============================] - 0s 152ms/step - loss: 1419242766336.0000 - val_loss: 1492792246272.0000\n","Epoch 6/1024\n","2/2 [==============================] - 0s 173ms/step - loss: 1419238572032.0000 - val_loss: 1492780187648.0000\n","Epoch 7/1024\n","2/2 [==============================] - 0s 148ms/step - loss: 1419226644480.0000 - val_loss: 1492747550720.0000\n","Epoch 8/1024\n","2/2 [==============================] - 0s 150ms/step - loss: 1419193483264.0000 - val_loss: 1492661174272.0000\n","Epoch 9/1024\n","2/2 [==============================] - 0s 146ms/step - loss: 1419106320384.0000 - val_loss: 1492426948608.0000\n","Epoch 10/1024\n","2/2 [==============================] - 0s 156ms/step - loss: 1418868817920.0000 - val_loss: 1491807895552.0000\n","Epoch 11/1024\n","2/2 [==============================] - 0s 150ms/step - loss: 1418238492672.0000 - val_loss: 1490187190272.0000\n","Epoch 12/1024\n","2/2 [==============================] - 0s 148ms/step - loss: 1416615559168.0000 - val_loss: 1485654589440.0000\n","Epoch 13/1024\n","2/2 [==============================] - 0s 162ms/step - loss: 1412110483456.0000 - val_loss: 1473176928256.0000\n","Epoch 14/1024\n","2/2 [==============================] - 0s 150ms/step - loss: 1399293083648.0000 - val_loss: 1438520836096.0000\n","Epoch 15/1024\n","2/2 [==============================] - 0s 150ms/step - loss: 1363931168768.0000 - val_loss: 1341944496128.0000\n","Epoch 16/1024\n","2/2 [==============================] - 0s 145ms/step - loss: 1266500501504.0000 - val_loss: 1065158443008.0000\n","Epoch 17/1024\n","2/2 [==============================] - 0s 147ms/step - loss: 990410702848.0000 - val_loss: 437636595712.0000\n","Epoch 18/1024\n","2/2 [==============================] - 0s 62ms/step - loss: 407074865152.0000 - val_loss: 658851495936.0000\n","Epoch 19/1024\n","2/2 [==============================] - 0s 157ms/step - loss: 734309580800.0000 - val_loss: 184480432128.0000\n","Epoch 20/1024\n","2/2 [==============================] - 0s 67ms/step - loss: 225709817856.0000 - val_loss: 322311454720.0000\n","Epoch 21/1024\n","2/2 [==============================] - 0s 59ms/step - loss: 325859737600.0000 - val_loss: 443190083584.0000\n","Epoch 22/1024\n","2/2 [==============================] - 0s 70ms/step - loss: 414821908480.0000 - val_loss: 377731350528.0000\n","Epoch 23/1024\n","2/2 [==============================] - 0s 69ms/step - loss: 363298455552.0000 - val_loss: 191472091136.0000\n","Epoch 24/1024\n","2/2 [==============================] - 0s 179ms/step - loss: 195798941696.0000 - val_loss: 109096615936.0000\n","Epoch 25/1024\n","2/2 [==============================] - 0s 69ms/step - loss: 148431978496.0000 - val_loss: 229997314048.0000\n","Epoch 26/1024\n","2/2 [==============================] - 0s 163ms/step - loss: 297009709056.0000 - val_loss: 92236783616.0000\n","Epoch 27/1024\n","2/2 [==============================] - 0s 67ms/step - loss: 129310359552.0000 - val_loss: 112420560896.0000\n","Epoch 28/1024\n","2/2 [==============================] - 0s 67ms/step - loss: 128542162944.0000 - val_loss: 167792459776.0000\n","Epoch 29/1024\n","2/2 [==============================] - 0s 78ms/step - loss: 177403641856.0000 - val_loss: 132155826176.0000\n","Epoch 30/1024\n","2/2 [==============================] - 0s 151ms/step - loss: 142465777664.0000 - val_loss: 64538480640.0000\n","Epoch 31/1024\n","2/2 [==============================] - 0s 60ms/step - loss: 94527209472.0000 - val_loss: 73093373952.0000\n","Epoch 32/1024\n","2/2 [==============================] - 0s 62ms/step - loss: 112887226368.0000 - val_loss: 74827898880.0000\n","Epoch 33/1024\n","2/2 [==============================] - 0s 156ms/step - loss: 114839134208.0000 - val_loss: 51643236352.0000\n","Epoch 34/1024\n","2/2 [==============================] - 0s 61ms/step - loss: 85828149248.0000 - val_loss: 72055316480.0000\n","Epoch 35/1024\n","2/2 [==============================] - 0s 61ms/step - loss: 102794575872.0000 - val_loss: 84004478976.0000\n","Epoch 36/1024\n","2/2 [==============================] - 0s 66ms/step - loss: 103369678848.0000 - val_loss: 60055711744.0000\n","Epoch 37/1024\n","2/2 [==============================] - 0s 160ms/step - loss: 87787241472.0000 - val_loss: 48773726208.0000\n","Epoch 38/1024\n","2/2 [==============================] - 0s 65ms/step - loss: 88042627072.0000 - val_loss: 64722071552.0000\n","Epoch 39/1024\n","2/2 [==============================] - 0s 181ms/step - loss: 117638602752.0000 - val_loss: 47571222528.0000\n","Epoch 40/1024\n","2/2 [==============================] - 0s 59ms/step - loss: 89179127808.0000 - val_loss: 53124345856.0000\n","Epoch 41/1024\n","2/2 [==============================] - 0s 65ms/step - loss: 79147302912.0000 - val_loss: 67885932544.0000\n","Epoch 42/1024\n","2/2 [==============================] - 0s 67ms/step - loss: 94975664128.0000 - val_loss: 51462860800.0000\n","Epoch 43/1024\n","2/2 [==============================] - 0s 159ms/step - loss: 76788473856.0000 - val_loss: 44635435008.0000\n","Epoch 44/1024\n","2/2 [==============================] - 0s 67ms/step - loss: 82040225792.0000 - val_loss: 50826063872.0000\n","Epoch 45/1024\n","2/2 [==============================] - 0s 160ms/step - loss: 95936282624.0000 - val_loss: 42960142336.0000\n","Epoch 46/1024\n","2/2 [==============================] - 0s 64ms/step - loss: 78875164672.0000 - val_loss: 47029456896.0000\n","Epoch 47/1024\n","2/2 [==============================] - 0s 64ms/step - loss: 80108109824.0000 - val_loss: 57232416768.0000\n","Epoch 48/1024\n","2/2 [==============================] - 0s 65ms/step - loss: 83322322944.0000 - val_loss: 47507755008.0000\n","Epoch 49/1024\n","2/2 [==============================] - 0s 194ms/step - loss: 73493495808.0000 - val_loss: 40759816192.0000\n","Epoch 50/1024\n","2/2 [==============================] - 0s 62ms/step - loss: 74056859648.0000 - val_loss: 41535713280.0000\n","Epoch 51/1024\n","2/2 [==============================] - 0s 64ms/step - loss: 73324314624.0000 - val_loss: 41211908096.0000\n","Epoch 52/1024\n","2/2 [==============================] - 0s 60ms/step - loss: 75693350912.0000 - val_loss: 57719689216.0000\n","Epoch 53/1024\n","2/2 [==============================] - 0s 62ms/step - loss: 77645611008.0000 - val_loss: 61451165696.0000\n","Epoch 54/1024\n","2/2 [==============================] - 0s 59ms/step - loss: 82970845184.0000 - val_loss: 43271204864.0000\n","Epoch 55/1024\n","2/2 [==============================] - 0s 63ms/step - loss: 73907478528.0000 - val_loss: 44213542912.0000\n","Epoch 56/1024\n","2/2 [==============================] - 0s 62ms/step - loss: 78371512320.0000 - val_loss: 47416963072.0000\n","Epoch 57/1024\n","2/2 [==============================] - 0s 167ms/step - loss: 86344368128.0000 - val_loss: 39213563904.0000\n","Epoch 58/1024\n","2/2 [==============================] - 0s 69ms/step - loss: 70729318400.0000 - val_loss: 51834793984.0000\n","Epoch 59/1024\n","2/2 [==============================] - 0s 63ms/step - loss: 76632121344.0000 - val_loss: 48783314944.0000\n","Epoch 60/1024\n","2/2 [==============================] - 0s 162ms/step - loss: 75385724928.0000 - val_loss: 39089516544.0000\n","Epoch 61/1024\n","2/2 [==============================] - 0s 161ms/step - loss: 71377887232.0000 - val_loss: 38417653760.0000\n","Epoch 62/1024\n","2/2 [==============================] - 0s 60ms/step - loss: 76273934336.0000 - val_loss: 38916341760.0000\n","Epoch 63/1024\n","2/2 [==============================] - 0s 62ms/step - loss: 78009917440.0000 - val_loss: 38537662464.0000\n","Epoch 64/1024\n","2/2 [==============================] - 0s 65ms/step - loss: 72836890624.0000 - val_loss: 43985039360.0000\n","Epoch 65/1024\n","2/2 [==============================] - 0s 157ms/step - loss: 74959732736.0000 - val_loss: 38023553024.0000\n","Epoch 66/1024\n","2/2 [==============================] - 0s 154ms/step - loss: 65926754304.0000 - val_loss: 37170495488.0000\n","Epoch 67/1024\n","2/2 [==============================] - 0s 162ms/step - loss: 73368117248.0000 - val_loss: 36298350592.0000\n","Epoch 68/1024\n","2/2 [==============================] - 0s 65ms/step - loss: 66934153216.0000 - val_loss: 38410502144.0000\n","Epoch 69/1024\n","2/2 [==============================] - 0s 61ms/step - loss: 69992529920.0000 - val_loss: 39926898688.0000\n","Epoch 70/1024\n","2/2 [==============================] - 0s 60ms/step - loss: 67398922240.0000 - val_loss: 38689841152.0000\n","Epoch 71/1024\n","2/2 [==============================] - 0s 60ms/step - loss: 71605927936.0000 - val_loss: 37461430272.0000\n","Epoch 72/1024\n","2/2 [==============================] - 0s 67ms/step - loss: 63809454080.0000 - val_loss: 39669895168.0000\n","Epoch 73/1024\n","2/2 [==============================] - 0s 61ms/step - loss: 71833649152.0000 - val_loss: 43683700736.0000\n","Epoch 74/1024\n","2/2 [==============================] - 0s 59ms/step - loss: 69536563200.0000 - val_loss: 37201436672.0000\n","Epoch 75/1024\n","2/2 [==============================] - 0s 153ms/step - loss: 72230494208.0000 - val_loss: 34833108992.0000\n","Epoch 76/1024\n","2/2 [==============================] - 0s 156ms/step - loss: 71683145728.0000 - val_loss: 34657230848.0000\n","Epoch 77/1024\n","2/2 [==============================] - 0s 65ms/step - loss: 66144956416.0000 - val_loss: 36619112448.0000\n","Epoch 78/1024\n","2/2 [==============================] - 0s 62ms/step - loss: 63075336192.0000 - val_loss: 38848765952.0000\n","Epoch 79/1024\n","2/2 [==============================] - 0s 60ms/step - loss: 65425711104.0000 - val_loss: 37766914048.0000\n","Epoch 80/1024\n","2/2 [==============================] - 0s 62ms/step - loss: 65651703808.0000 - val_loss: 35161268224.0000\n","Epoch 81/1024\n","2/2 [==============================] - 0s 170ms/step - loss: 65317158912.0000 - val_loss: 33913911296.0000\n","Epoch 82/1024\n","2/2 [==============================] - 0s 159ms/step - loss: 64568459264.0000 - val_loss: 33608048640.0000\n","Epoch 83/1024\n","2/2 [==============================] - 0s 65ms/step - loss: 63246856192.0000 - val_loss: 33621178368.0000\n","Epoch 84/1024\n","2/2 [==============================] - 0s 63ms/step - loss: 66809573376.0000 - val_loss: 35452952576.0000\n","Epoch 85/1024\n","2/2 [==============================] - 0s 67ms/step - loss: 66004221952.0000 - val_loss: 34571079680.0000\n","Epoch 86/1024\n","2/2 [==============================] - 0s 165ms/step - loss: 68398190592.0000 - val_loss: 33126586368.0000\n","Epoch 87/1024\n","2/2 [==============================] - 0s 168ms/step - loss: 62692462592.0000 - val_loss: 32741539840.0000\n","Epoch 88/1024\n","2/2 [==============================] - 0s 74ms/step - loss: 63316774912.0000 - val_loss: 33132707840.0000\n","Epoch 89/1024\n","2/2 [==============================] - 0s 72ms/step - loss: 64939560960.0000 - val_loss: 36333060096.0000\n","Epoch 90/1024\n","2/2 [==============================] - 0s 65ms/step - loss: 64726765568.0000 - val_loss: 35346669568.0000\n","Epoch 91/1024\n","2/2 [==============================] - 0s 153ms/step - loss: 67525783552.0000 - val_loss: 32220207104.0000\n","Epoch 92/1024\n","2/2 [==============================] - 0s 63ms/step - loss: 58723049472.0000 - val_loss: 32290852864.0000\n","Epoch 93/1024\n","2/2 [==============================] - 0s 157ms/step - loss: 65958031360.0000 - val_loss: 32142272512.0000\n","Epoch 94/1024\n","2/2 [==============================] - 0s 65ms/step - loss: 65777745920.0000 - val_loss: 37215051776.0000\n","Epoch 95/1024\n","2/2 [==============================] - 0s 64ms/step - loss: 63071313920.0000 - val_loss: 35636469760.0000\n","Epoch 96/1024\n","2/2 [==============================] - 0s 153ms/step - loss: 66411790336.0000 - val_loss: 31083558912.0000\n","Epoch 97/1024\n","2/2 [==============================] - 0s 155ms/step - loss: 59386171392.0000 - val_loss: 31050706944.0000\n","Epoch 98/1024\n","2/2 [==============================] - 0s 62ms/step - loss: 63403102208.0000 - val_loss: 36829577216.0000\n","Epoch 99/1024\n","2/2 [==============================] - 0s 61ms/step - loss: 65169117184.0000 - val_loss: 42807545856.0000\n","Epoch 100/1024\n","2/2 [==============================] - 0s 63ms/step - loss: 66012237824.0000 - val_loss: 35730145280.0000\n","Epoch 101/1024\n","2/2 [==============================] - 0s 146ms/step - loss: 62435016704.0000 - val_loss: 30707806208.0000\n","Epoch 102/1024\n","2/2 [==============================] - 0s 60ms/step - loss: 61634179072.0000 - val_loss: 31722596352.0000\n","Epoch 103/1024\n","2/2 [==============================] - 0s 180ms/step - loss: 72779849728.0000 - val_loss: 29876447232.0000\n","Epoch 104/1024\n","2/2 [==============================] - 0s 72ms/step - loss: 63187054592.0000 - val_loss: 35739922432.0000\n","Epoch 105/1024\n","2/2 [==============================] - 0s 67ms/step - loss: 66732756992.0000 - val_loss: 42035425280.0000\n","Epoch 106/1024\n","2/2 [==============================] - 0s 61ms/step - loss: 66698891264.0000 - val_loss: 32959287296.0000\n","Epoch 107/1024\n","2/2 [==============================] - 0s 61ms/step - loss: 60294422528.0000 - val_loss: 31932012544.0000\n","Epoch 108/1024\n","2/2 [==============================] - 0s 159ms/step - loss: 71028899840.0000 - val_loss: 28972132352.0000\n","Epoch 109/1024\n","2/2 [==============================] - 0s 65ms/step - loss: 61049393152.0000 - val_loss: 40166932480.0000\n","Epoch 110/1024\n","2/2 [==============================] - 0s 66ms/step - loss: 70144974848.0000 - val_loss: 39379234816.0000\n","Epoch 111/1024\n","2/2 [==============================] - 0s 64ms/step - loss: 67527385088.0000 - val_loss: 29419202560.0000\n","Epoch 112/1024\n","2/2 [==============================] - 0s 158ms/step - loss: 58958188544.0000 - val_loss: 28310312960.0000\n","Epoch 113/1024\n","2/2 [==============================] - 0s 62ms/step - loss: 63996690432.0000 - val_loss: 34078957568.0000\n","Epoch 114/1024\n","2/2 [==============================] - 0s 63ms/step - loss: 61341085696.0000 - val_loss: 36453928960.0000\n","Epoch 115/1024\n","2/2 [==============================] - 0s 172ms/step - loss: 67084546048.0000 - val_loss: 27905390592.0000\n","Epoch 116/1024\n","2/2 [==============================] - 0s 66ms/step - loss: 60273147904.0000 - val_loss: 28334278656.0000\n","Epoch 117/1024\n","2/2 [==============================] - 0s 61ms/step - loss: 67096182784.0000 - val_loss: 28426334208.0000\n","Epoch 118/1024\n","2/2 [==============================] - 0s 60ms/step - loss: 56184205312.0000 - val_loss: 31947479040.0000\n","Epoch 119/1024\n","2/2 [==============================] - 0s 67ms/step - loss: 57302786048.0000 - val_loss: 29382727680.0000\n","Epoch 120/1024\n","2/2 [==============================] - 0s 155ms/step - loss: 56695898112.0000 - val_loss: 26933903360.0000\n","Epoch 121/1024\n","2/2 [==============================] - 0s 71ms/step - loss: 59382980608.0000 - val_loss: 27067922432.0000\n","Epoch 122/1024\n","2/2 [==============================] - 0s 166ms/step - loss: 58928222208.0000 - val_loss: 26887469056.0000\n","Epoch 123/1024\n","2/2 [==============================] - 0s 64ms/step - loss: 60998094848.0000 - val_loss: 30441410560.0000\n","Epoch 124/1024\n","2/2 [==============================] - 0s 67ms/step - loss: 58745016320.0000 - val_loss: 34254831616.0000\n","Epoch 125/1024\n","2/2 [==============================] - 0s 70ms/step - loss: 60627513344.0000 - val_loss: 30781659136.0000\n","Epoch 126/1024\n","2/2 [==============================] - 0s 160ms/step - loss: 55214915584.0000 - val_loss: 25669050368.0000\n","Epoch 127/1024\n","2/2 [==============================] - 0s 63ms/step - loss: 61424779264.0000 - val_loss: 26073200640.0000\n","Epoch 128/1024\n","2/2 [==============================] - 0s 60ms/step - loss: 54101651456.0000 - val_loss: 29956022272.0000\n","Epoch 129/1024\n","2/2 [==============================] - 0s 61ms/step - loss: 59260829696.0000 - val_loss: 26487347200.0000\n","Epoch 130/1024\n","2/2 [==============================] - 0s 58ms/step - loss: 57964437504.0000 - val_loss: 26565136384.0000\n","Epoch 131/1024\n","2/2 [==============================] - 0s 60ms/step - loss: 58783653888.0000 - val_loss: 28939034624.0000\n","Epoch 132/1024\n","2/2 [==============================] - 0s 59ms/step - loss: 62501765120.0000 - val_loss: 26187423744.0000\n","Epoch 133/1024\n","2/2 [==============================] - 0s 149ms/step - loss: 53510615040.0000 - val_loss: 24214001664.0000\n","Epoch 134/1024\n","2/2 [==============================] - 0s 161ms/step - loss: 56820043776.0000 - val_loss: 23909728256.0000\n","Epoch 135/1024\n","2/2 [==============================] - 0s 69ms/step - loss: 62374670336.0000 - val_loss: 29254981632.0000\n","Epoch 136/1024\n","2/2 [==============================] - 0s 70ms/step - loss: 55377985536.0000 - val_loss: 47155970048.0000\n","Epoch 137/1024\n","2/2 [==============================] - 0s 65ms/step - loss: 67817988096.0000 - val_loss: 34829791232.0000\n","Epoch 138/1024\n","2/2 [==============================] - 0s 63ms/step - loss: 56805634048.0000 - val_loss: 24981594112.0000\n","Epoch 139/1024\n","2/2 [==============================] - 0s 156ms/step - loss: 64155930624.0000 - val_loss: 23144355840.0000\n","Epoch 140/1024\n","2/2 [==============================] - 0s 62ms/step - loss: 58541199360.0000 - val_loss: 36949106688.0000\n","Epoch 141/1024\n","2/2 [==============================] - 0s 59ms/step - loss: 61513994240.0000 - val_loss: 38761512960.0000\n","Epoch 142/1024\n","2/2 [==============================] - 0s 62ms/step - loss: 58571186176.0000 - val_loss: 24190846976.0000\n","Epoch 143/1024\n","2/2 [==============================] - 0s 60ms/step - loss: 54398529536.0000 - val_loss: 23946426368.0000\n","Epoch 144/1024\n","2/2 [==============================] - 0s 161ms/step - loss: 54924673024.0000 - val_loss: 21944023040.0000\n","Epoch 145/1024\n","2/2 [==============================] - 0s 64ms/step - loss: 55924449280.0000 - val_loss: 36279824384.0000\n","Epoch 146/1024\n","2/2 [==============================] - 0s 61ms/step - loss: 60578582528.0000 - val_loss: 25586735104.0000\n","Epoch 147/1024\n","2/2 [==============================] - 0s 162ms/step - loss: 51919536128.0000 - val_loss: 21766084608.0000\n","Epoch 148/1024\n","2/2 [==============================] - 0s 157ms/step - loss: 53513199616.0000 - val_loss: 20426639360.0000\n","Epoch 149/1024\n","2/2 [==============================] - 0s 64ms/step - loss: 55549210624.0000 - val_loss: 27811874816.0000\n","Epoch 150/1024\n","2/2 [==============================] - 0s 62ms/step - loss: 53016817664.0000 - val_loss: 24421271552.0000\n","Epoch 151/1024\n","2/2 [==============================] - 0s 170ms/step - loss: 47939166208.0000 - val_loss: 19435968512.0000\n","Epoch 152/1024\n","2/2 [==============================] - 0s 181ms/step - loss: 51481661440.0000 - val_loss: 19415746560.0000\n","Epoch 153/1024\n","2/2 [==============================] - 0s 70ms/step - loss: 50182021120.0000 - val_loss: 21528866816.0000\n","Epoch 154/1024\n","2/2 [==============================] - 0s 165ms/step - loss: 49101864960.0000 - val_loss: 19109332992.0000\n","Epoch 155/1024\n","2/2 [==============================] - 0s 67ms/step - loss: 48791085056.0000 - val_loss: 19344648192.0000\n","Epoch 156/1024\n","2/2 [==============================] - 0s 69ms/step - loss: 49988481024.0000 - val_loss: 30832056320.0000\n","Epoch 157/1024\n","2/2 [==============================] - 0s 66ms/step - loss: 57860227072.0000 - val_loss: 28569114624.0000\n","Epoch 158/1024\n","2/2 [==============================] - 0s 176ms/step - loss: 49008390144.0000 - val_loss: 17328605184.0000\n","Epoch 159/1024\n","2/2 [==============================] - 0s 65ms/step - loss: 50825523200.0000 - val_loss: 19776417792.0000\n","Epoch 160/1024\n","2/2 [==============================] - 0s 60ms/step - loss: 53518946304.0000 - val_loss: 22202146816.0000\n","Epoch 161/1024\n","2/2 [==============================] - 0s 62ms/step - loss: 50362740736.0000 - val_loss: 31170947072.0000\n","Epoch 162/1024\n","2/2 [==============================] - 0s 152ms/step - loss: 54049972224.0000 - val_loss: 15716670464.0000\n","Epoch 163/1024\n","2/2 [==============================] - 0s 62ms/step - loss: 45045047296.0000 - val_loss: 22691829760.0000\n","Epoch 164/1024\n","2/2 [==============================] - 0s 156ms/step - loss: 66116968448.0000 - val_loss: 14900382720.0000\n","Epoch 165/1024\n","2/2 [==============================] - 0s 60ms/step - loss: 45193793536.0000 - val_loss: 27610292224.0000\n","Epoch 166/1024\n","2/2 [==============================] - 0s 62ms/step - loss: 52286115840.0000 - val_loss: 17337323520.0000\n","Epoch 167/1024\n","2/2 [==============================] - 0s 160ms/step - loss: 43415597056.0000 - val_loss: 13040902144.0000\n","Epoch 168/1024\n","2/2 [==============================] - 0s 161ms/step - loss: 42618195968.0000 - val_loss: 12583821312.0000\n","Epoch 169/1024\n","2/2 [==============================] - 0s 163ms/step - loss: 43777277952.0000 - val_loss: 12334028800.0000\n","Epoch 170/1024\n","2/2 [==============================] - 0s 72ms/step - loss: 42838908928.0000 - val_loss: 12485752832.0000\n","Epoch 171/1024\n","2/2 [==============================] - 0s 65ms/step - loss: 43115696128.0000 - val_loss: 17273917440.0000\n","Epoch 172/1024\n","2/2 [==============================] - 0s 164ms/step - loss: 42565115904.0000 - val_loss: 11214134272.0000\n","Epoch 173/1024\n","2/2 [==============================] - 0s 175ms/step - loss: 42789892096.0000 - val_loss: 10205861888.0000\n","Epoch 174/1024\n","2/2 [==============================] - 0s 64ms/step - loss: 38165032960.0000 - val_loss: 12706226176.0000\n","Epoch 175/1024\n","2/2 [==============================] - 0s 63ms/step - loss: 40653877248.0000 - val_loss: 13976991744.0000\n","Epoch 176/1024\n","2/2 [==============================] - 0s 153ms/step - loss: 35245113344.0000 - val_loss: 9847372800.0000\n","Epoch 177/1024\n","2/2 [==============================] - 0s 159ms/step - loss: 39932248064.0000 - val_loss: 8389548544.0000\n","Epoch 178/1024\n","2/2 [==============================] - 0s 164ms/step - loss: 37144539136.0000 - val_loss: 7806174720.0000\n","Epoch 179/1024\n","2/2 [==============================] - 0s 178ms/step - loss: 35309662208.0000 - val_loss: 7616276480.0000\n","Epoch 180/1024\n","2/2 [==============================] - 0s 65ms/step - loss: 33054103552.0000 - val_loss: 10047986688.0000\n","Epoch 181/1024\n","2/2 [==============================] - 0s 63ms/step - loss: 36142088192.0000 - val_loss: 10845562880.0000\n","Epoch 182/1024\n","2/2 [==============================] - 0s 151ms/step - loss: 35086901248.0000 - val_loss: 7413496832.0000\n","Epoch 183/1024\n","2/2 [==============================] - 0s 179ms/step - loss: 34976178176.0000 - val_loss: 5522122240.0000\n","Epoch 184/1024\n","2/2 [==============================] - 0s 169ms/step - loss: 33748946944.0000 - val_loss: 4848034304.0000\n","Epoch 185/1024\n","2/2 [==============================] - 0s 71ms/step - loss: 33102073856.0000 - val_loss: 7059889152.0000\n","Epoch 186/1024\n","2/2 [==============================] - 0s 74ms/step - loss: 32167634944.0000 - val_loss: 7005184512.0000\n","Epoch 187/1024\n","2/2 [==============================] - 0s 181ms/step - loss: 32582467584.0000 - val_loss: 4636326912.0000\n","Epoch 188/1024\n","2/2 [==============================] - 0s 153ms/step - loss: 30537967616.0000 - val_loss: 4328878592.0000\n","Epoch 189/1024\n","2/2 [==============================] - 0s 62ms/step - loss: 30785691648.0000 - val_loss: 4360333824.0000\n","Epoch 190/1024\n","2/2 [==============================] - 0s 64ms/step - loss: 31109216256.0000 - val_loss: 5020466176.0000\n","Epoch 191/1024\n","2/2 [==============================] - 0s 157ms/step - loss: 30795040768.0000 - val_loss: 3223358464.0000\n","Epoch 192/1024\n","2/2 [==============================] - 0s 157ms/step - loss: 25053732864.0000 - val_loss: 2360774912.0000\n","Epoch 193/1024\n","2/2 [==============================] - 0s 61ms/step - loss: 25844824064.0000 - val_loss: 8163292160.0000\n","Epoch 194/1024\n","2/2 [==============================] - 0s 172ms/step - loss: 29738541056.0000 - val_loss: 1871358976.0000\n","Epoch 195/1024\n","2/2 [==============================] - 0s 62ms/step - loss: 27697934336.0000 - val_loss: 1984771712.0000\n","Epoch 196/1024\n","2/2 [==============================] - 0s 60ms/step - loss: 30824876032.0000 - val_loss: 2828629504.0000\n","Epoch 197/1024\n","2/2 [==============================] - 0s 62ms/step - loss: 27635703808.0000 - val_loss: 2999755008.0000\n","Epoch 198/1024\n","2/2 [==============================] - 0s 62ms/step - loss: 27220498432.0000 - val_loss: 2279622912.0000\n","Epoch 199/1024\n","2/2 [==============================] - 0s 64ms/step - loss: 26620254208.0000 - val_loss: 2443776768.0000\n","Epoch 200/1024\n","2/2 [==============================] - 0s 72ms/step - loss: 27364481024.0000 - val_loss: 3475581440.0000\n","Epoch 201/1024\n","2/2 [==============================] - 0s 66ms/step - loss: 24509884416.0000 - val_loss: 2626059264.0000\n","Epoch 202/1024\n","2/2 [==============================] - 0s 177ms/step - loss: 24269268992.0000 - val_loss: 1162859648.0000\n","Epoch 203/1024\n","2/2 [==============================] - 0s 63ms/step - loss: 26923411456.0000 - val_loss: 1849862912.0000\n","Epoch 204/1024\n","2/2 [==============================] - 0s 67ms/step - loss: 27714609152.0000 - val_loss: 3520151552.0000\n","Epoch 205/1024\n","2/2 [==============================] - 0s 65ms/step - loss: 25799407616.0000 - val_loss: 1284094336.0000\n","Epoch 206/1024\n","2/2 [==============================] - 0s 63ms/step - loss: 26488846336.0000 - val_loss: 3775153152.0000\n","Epoch 207/1024\n","2/2 [==============================] - 0s 61ms/step - loss: 27686522880.0000 - val_loss: 1626543232.0000\n","Epoch 208/1024\n","2/2 [==============================] - 0s 66ms/step - loss: 24971290624.0000 - val_loss: 2735121152.0000\n","Epoch 209/1024\n","2/2 [==============================] - 0s 62ms/step - loss: 28618842112.0000 - val_loss: 6308238848.0000\n","Epoch 210/1024\n","2/2 [==============================] - 0s 60ms/step - loss: 28352397312.0000 - val_loss: 1293074432.0000\n","Epoch 211/1024\n","2/2 [==============================] - 0s 61ms/step - loss: 27913136128.0000 - val_loss: 3927319040.0000\n","Epoch 212/1024\n","2/2 [==============================] - 0s 74ms/step - loss: 24958208000.0000 - val_loss: 7659567616.0000\n","Epoch 213/1024\n","2/2 [==============================] - 0s 65ms/step - loss: 28895076352.0000 - val_loss: 1252528512.0000\n","Epoch 214/1024\n","2/2 [==============================] - 0s 67ms/step - loss: 23381032960.0000 - val_loss: 1832029824.0000\n","Epoch 215/1024\n","2/2 [==============================] - 0s 63ms/step - loss: 24898570240.0000 - val_loss: 9948449792.0000\n","Epoch 216/1024\n","2/2 [==============================] - 0s 66ms/step - loss: 30509559808.0000 - val_loss: 5456935936.0000\n","Epoch 217/1024\n","2/2 [==============================] - 0s 71ms/step - loss: 26236336128.0000 - val_loss: 1455635840.0000\n","Epoch 218/1024\n","2/2 [==============================] - 0s 72ms/step - loss: 25940402176.0000 - val_loss: 1343477760.0000\n","Epoch 219/1024\n","2/2 [==============================] - 0s 66ms/step - loss: 24025063424.0000 - val_loss: 8282253312.0000\n","Epoch 220/1024\n","2/2 [==============================] - 0s 63ms/step - loss: 26247776256.0000 - val_loss: 8137707008.0000\n","Epoch 221/1024\n","2/2 [==============================] - 0s 61ms/step - loss: 23432691712.0000 - val_loss: 2694243584.0000\n","Epoch 222/1024\n","2/2 [==============================] - 0s 59ms/step - loss: 23201908736.0000 - val_loss: 1357927424.0000\n","Epoch 223/1024\n","2/2 [==============================] - 0s 63ms/step - loss: 24181659648.0000 - val_loss: 4470688256.0000\n","Epoch 224/1024\n","2/2 [==============================] - 0s 61ms/step - loss: 23232083968.0000 - val_loss: 8421565440.0000\n","Epoch 225/1024\n","2/2 [==============================] - 0s 59ms/step - loss: 25982382080.0000 - val_loss: 4695529984.0000\n","Epoch 226/1024\n","2/2 [==============================] - 0s 156ms/step - loss: 22957146112.0000 - val_loss: 1050284224.0000\n","Epoch 227/1024\n","2/2 [==============================] - 0s 61ms/step - loss: 26865539072.0000 - val_loss: 2220292352.0000\n","Epoch 228/1024\n","2/2 [==============================] - 0s 65ms/step - loss: 23917498368.0000 - val_loss: 1164768896.0000\n","Epoch 229/1024\n","2/2 [==============================] - 0s 63ms/step - loss: 27807672320.0000 - val_loss: 1622249728.0000\n","Epoch 230/1024\n","2/2 [==============================] - 0s 62ms/step - loss: 26347456512.0000 - val_loss: 8551314432.0000\n","Epoch 231/1024\n","2/2 [==============================] - 0s 67ms/step - loss: 27454263296.0000 - val_loss: 12468907008.0000\n","Epoch 232/1024\n","2/2 [==============================] - 0s 67ms/step - loss: 26136403968.0000 - val_loss: 3170317056.0000\n","Epoch 233/1024\n","2/2 [==============================] - 0s 65ms/step - loss: 22716096512.0000 - val_loss: 7574617600.0000\n","Epoch 234/1024\n","2/2 [==============================] - 0s 62ms/step - loss: 23918530560.0000 - val_loss: 4690438656.0000\n","Epoch 235/1024\n","2/2 [==============================] - 0s 67ms/step - loss: 23180761088.0000 - val_loss: 1523603200.0000\n","Epoch 236/1024\n","2/2 [==============================] - 0s 64ms/step - loss: 25157373952.0000 - val_loss: 1495435776.0000\n","Epoch 237/1024\n","2/2 [==============================] - 0s 62ms/step - loss: 24843483136.0000 - val_loss: 10904406016.0000\n","Epoch 238/1024\n","2/2 [==============================] - 0s 61ms/step - loss: 28351430656.0000 - val_loss: 6738037760.0000\n","Epoch 239/1024\n","2/2 [==============================] - 0s 66ms/step - loss: 27687634944.0000 - val_loss: 1196268672.0000\n","Epoch 240/1024\n","2/2 [==============================] - 0s 63ms/step - loss: 25641938944.0000 - val_loss: 4742550528.0000\n","Epoch 241/1024\n","2/2 [==============================] - 0s 62ms/step - loss: 25184446464.0000 - val_loss: 4915159552.0000\n","Epoch 242/1024\n","2/2 [==============================] - 0s 70ms/step - loss: 27894870016.0000 - val_loss: 1166424448.0000\n","Epoch 243/1024\n","2/2 [==============================] - 0s 63ms/step - loss: 28414750720.0000 - val_loss: 4811766272.0000\n","Epoch 244/1024\n","2/2 [==============================] - 0s 59ms/step - loss: 26008647680.0000 - val_loss: 7912375296.0000\n","Epoch 245/1024\n","2/2 [==============================] - 0s 60ms/step - loss: 25216243712.0000 - val_loss: 1246854784.0000\n","Epoch 246/1024\n","2/2 [==============================] - 0s 62ms/step - loss: 25120516096.0000 - val_loss: 1227852032.0000\n","Epoch 247/1024\n","2/2 [==============================] - 0s 62ms/step - loss: 23987505152.0000 - val_loss: 4580380160.0000\n","Epoch 248/1024\n","2/2 [==============================] - 0s 61ms/step - loss: 24797007872.0000 - val_loss: 2466961920.0000\n","Epoch 249/1024\n","2/2 [==============================] - 0s 80ms/step - loss: 25616144384.0000 - val_loss: 2818326272.0000\n","Epoch 250/1024\n","2/2 [==============================] - 0s 64ms/step - loss: 21991112704.0000 - val_loss: 5689300480.0000\n","Epoch 251/1024\n","2/2 [==============================] - 0s 62ms/step - loss: 22628012032.0000 - val_loss: 1299979648.0000\n","Epoch 252/1024\n","2/2 [==============================] - 0s 67ms/step - loss: 22602522624.0000 - val_loss: 1117088256.0000\n","Epoch 253/1024\n","2/2 [==============================] - 0s 72ms/step - loss: 25178595328.0000 - val_loss: 5695634944.0000\n","Epoch 254/1024\n","2/2 [==============================] - 0s 64ms/step - loss: 24416333824.0000 - val_loss: 3195022848.0000\n","Epoch 255/1024\n","2/2 [==============================] - 0s 66ms/step - loss: 22707873792.0000 - val_loss: 2017227904.0000\n","Epoch 256/1024\n","2/2 [==============================] - 0s 65ms/step - loss: 27214942208.0000 - val_loss: 10231785472.0000\n","Epoch 257/1024\n","2/2 [==============================] - 0s 67ms/step - loss: 25939128320.0000 - val_loss: 27566764032.0000\n","Epoch 258/1024\n","2/2 [==============================] - 0s 80ms/step - loss: 37293182976.0000 - val_loss: 1137780608.0000\n"]}],"source":["from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","\n","model.compile(loss='mse', optimizer= 'adam')\n","\n","ES = EarlyStopping(monitor='val_loss', mode='auto', patience=32, restore_best_weights=True)\n","MCP = ModelCheckpoint(monitor='val_loss', mode='auto', save_best_only=True,filepath = PATH + 'stock_ModelCheckPoint.hdf5') # 모델과 가중치 저장\n","\n","model.fit([samsung_x_train, amore_x_train], samsung_y_train , epochs=1024, batch_size=1024, validation_split=0.2, callbacks=[ES, MCP])\n","\n","model.save_weights(PATH + 'stock_weight.h5') # 가중치만 저장"]},{"cell_type":"markdown","metadata":{"id":"C-lSdQEaGfuF"},"source":["# 4. 평가, 예측"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31619,"status":"ok","timestamp":1674922649872,"user":{"displayName":"노영선(과학기술대학 컴퓨터정보통신공학부)","userId":"09542015644926611058"},"user_tz":-540},"id":"yQQQX0BZGbwL","outputId":"10e26111-cd3c-4d4e-9af5-49f53c394710"},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 28ms/step - loss: 3362518784.0000\n","loss :  3362518784.0\n","삼성전자 시가 : [[68032.42]]\n"]}],"source":["loss=model.evaluate([samsung_x_test, amore_x_test], samsung_y_test, batch_size=1024)\n","samsung_y_predict = model.predict([samsung_x_predict, amore_x_predict])\n","\n","print(\"loss : \", loss)\n","print(\"삼성전자 시가 :\" , samsung_y_predict)"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPvQxyZy+xkCZyyt31sFwVy","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"tf27","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]"},"vscode":{"interpreter":{"hash":"b47fb4e6c68d4941015efb0bbf71549277582fe8531338196fc3c7fa71b6aab8"}}},"nbformat":4,"nbformat_minor":0}
