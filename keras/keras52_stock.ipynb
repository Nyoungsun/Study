{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input, LSTM, concatenate\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn. preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<< origin >>\n",
      "samsung_x.shape:  (1980, 5)\n",
      "amore_x.shape:  (1980, 5)\n",
      "samsung_y.shape:  (1980, 1)\n",
      "<< split_x >>\n",
      "samsung_x.shape:  (1976, 5, 5)\n",
      "amore._xshape:  (1976, 5, 5)\n",
      "<< train test split >>\n",
      "samsung_x_train.shape:  (1382, 5, 5) samsung_x_test.shape:  (593, 5, 5)\n",
      "amore_x_train.shape:  (1382, 5, 5) amore_x_test.shape:  (593, 5, 5)\n",
      "samsung_y_train.shape:  (1383, 5, 1) samsung_y_test.shape:  (593, 5, 1)\n"
     ]
    }
   ],
   "source": [
    "# PATH = 'C:/study/keras/keras_data/stock/'            # camp PATH\n",
    "PATH = 'C:/Users/nys/study/keras/keras_data/stock/'    # mypc PATH\n",
    "\n",
    "samsung_dataset = pd.read_csv(PATH + '삼성전자 주가.csv', header=0, index_col=None, encoding='cp949', thousands = ',').loc[::-1]\n",
    "amore_dataset = pd.read_csv(PATH + '아모레퍼시픽 주가.csv', header=0, index_col=None, encoding='cp949', thousands = ',').loc[::-1] \n",
    "# print(samsung)\n",
    "# print(amore)\n",
    "\n",
    "samsung_x = samsung_dataset[['종가', '저가', '고가', '기관','외인(수량)']].to_numpy()\n",
    "amore_x = amore_dataset.loc[samsung_x.shape[0]:1,['종가', '저가', '고가', '기관', '외인(수량)']].to_numpy()\n",
    "samsung_y = samsung_dataset[['시가']].to_numpy()\n",
    "# print(samsung)\n",
    "# print(samsung_y)\n",
    "# print(samsung.dtypes) # int64\n",
    "# print(samsung_y.dtypes) # int64\n",
    "        \n",
    "# print(amore.dtypes) # int64\n",
    "\n",
    "print('<< origin >>')\n",
    "print('samsung_x.shape: ', samsung_x.shape)\n",
    "print('amore_x.shape: ', amore_x.shape)\n",
    "print('samsung_y.shape: ', samsung_y.shape)\n",
    "\n",
    "# --------------------------- 스케일링 --------------------------------- #\n",
    "samsung_x = MinMaxScaler().fit_transform(samsung_x)\n",
    "amore_x = MinMaxScaler().fit_transform(amore_x)\n",
    "\n",
    "# --------------------------- for RNN---------------------------------- #\n",
    "def split_x(dataset, timesteps):\n",
    "    tmp = []\n",
    "    for i in range(len(dataset) - timesteps + 1):\n",
    "        subset = dataset[i : (i + timesteps)]\n",
    "        tmp.append(subset)\n",
    "    return np.array(tmp)\n",
    "\n",
    "samsung_x = split_x(samsung_x, 5) \n",
    "amore_x = split_x(amore_x, 5)     \n",
    "samsung_y = split_x(samsung_y, 5) \n",
    "\n",
    "print('<< split_x >>')\n",
    "print('samsung_x.shape: ', samsung_x.shape)\n",
    "print('amore._xshape: ', amore_x.shape)\n",
    "\n",
    "samsung_x_predict = samsung_x[-1]\n",
    "amore_x_predict = amore_x[-1]\n",
    "samsung_x = samsung_x[:-1, :, :]\n",
    "amore_x = amore_x[:-1, :, :]\n",
    "\n",
    "samsung_x_train, samsung_x_test = train_test_split(samsung_x, train_size=0.7)\n",
    "amore_x_train, amore_x_test = train_test_split(amore_x, train_size=0.7)\n",
    "samsung_y_train, samsung_y_test = train_test_split(samsung_y, train_size=0.7)\n",
    "\n",
    "\n",
    "print('<< train test split >>')\n",
    "print('samsung_x_train.shape: ', samsung_x_train.shape, 'samsung_x_test.shape: ', samsung_x_test.shape)\n",
    "print('amore_x_train.shape: ', amore_x_train.shape, 'amore_x_test.shape: ', amore_x_test.shape)\n",
    "print('samsung_y_train.shape: ', samsung_y_train.shape, 'samsung_y_test.shape: ', samsung_y_test.shape)\n",
    "\n",
    "# encoding='CP949': UTF-8 encoding error\n",
    "# loc[::-1]: 행 역순 정렬 \n",
    "# 여러 개의 열을 추출할 때는 대괄호 2개\n",
    "# train_test_split을 위해 데이터들의 shape 맞추기\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_21 (InputLayer)          [(None, 5, 5)]       0           []                               \n",
      "                                                                                                  \n",
      " input_22 (InputLayer)          [(None, 5, 5)]       0           []                               \n",
      "                                                                                                  \n",
      " lstm_40 (LSTM)                 (None, 5, 128)       68608       ['input_21[0][0]']               \n",
      "                                                                                                  \n",
      " lstm_42 (LSTM)                 (None, 5, 128)       68608       ['input_22[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_40 (Dropout)           (None, 5, 128)       0           ['lstm_40[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_42 (Dropout)           (None, 5, 128)       0           ['lstm_42[0][0]']                \n",
      "                                                                                                  \n",
      " lstm_41 (LSTM)                 (None, 256)          394240      ['dropout_40[0][0]']             \n",
      "                                                                                                  \n",
      " lstm_43 (LSTM)                 (None, 256)          394240      ['dropout_42[0][0]']             \n",
      "                                                                                                  \n",
      " dense_150 (Dense)              (None, 1024)         263168      ['lstm_41[0][0]']                \n",
      "                                                                                                  \n",
      " dense_155 (Dense)              (None, 1024)         263168      ['lstm_43[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_41 (Dropout)           (None, 1024)         0           ['dense_150[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_43 (Dropout)           (None, 1024)         0           ['dense_155[0][0]']              \n",
      "                                                                                                  \n",
      " dense_151 (Dense)              (None, 512)          524800      ['dropout_41[0][0]']             \n",
      "                                                                                                  \n",
      " dense_156 (Dense)              (None, 512)          524800      ['dropout_43[0][0]']             \n",
      "                                                                                                  \n",
      " dense_152 (Dense)              (None, 128)          65664       ['dense_151[0][0]']              \n",
      "                                                                                                  \n",
      " dense_157 (Dense)              (None, 128)          65664       ['dense_156[0][0]']              \n",
      "                                                                                                  \n",
      " dense_153 (Dense)              (None, 32)           4128        ['dense_152[0][0]']              \n",
      "                                                                                                  \n",
      " dense_158 (Dense)              (None, 32)           4128        ['dense_157[0][0]']              \n",
      "                                                                                                  \n",
      " dense_154 (Dense)              (None, 1)            33          ['dense_153[0][0]']              \n",
      "                                                                                                  \n",
      " dense_159 (Dense)              (None, 1)            33          ['dense_158[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_10 (Concatenate)   (None, 2)            0           ['dense_154[0][0]',              \n",
      "                                                                  'dense_159[0][0]']              \n",
      "                                                                                                  \n",
      " dense_160 (Dense)              (None, 256)          768         ['concatenate_10[0][0]']         \n",
      "                                                                                                  \n",
      " dense_161 (Dense)              (None, 512)          131584      ['dense_160[0][0]']              \n",
      "                                                                                                  \n",
      " dense_162 (Dense)              (None, 128)          65664       ['dense_161[0][0]']              \n",
      "                                                                                                  \n",
      " dense_163 (Dense)              (None, 32)           4128        ['dense_162[0][0]']              \n",
      "                                                                                                  \n",
      " dense_164 (Dense)              (None, 1)            33          ['dense_163[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,843,459\n",
      "Trainable params: 2,843,459\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 삼성전자\n",
    "samsung_input = Input(shape=(5, 5))\n",
    "samsung_layer1 = LSTM(128, return_sequences=True,activation='relu')(samsung_input)\n",
    "samsung_layer1 = Dropout(0.2)(samsung_layer1)\n",
    "samsung_layer2 = LSTM(256, activation='relu')(samsung_layer1)\n",
    "samsung_layer3 = Dense(1024, activation='relu')(samsung_layer2)\n",
    "samsung_layer4 = Dropout(0.2)(samsung_layer3)\n",
    "samsung_layer5 = Dense(512, activation='relu')(samsung_layer4)\n",
    "samsung_layer6 = Dense(128, activation='relu')(samsung_layer5)\n",
    "samsung_layer6 = Dense(32, activation='relu')(samsung_layer6)\n",
    "samsung_output = Dense(1)(samsung_layer6)\n",
    "\n",
    "# 아모레퍼시픽\n",
    "amore_input = Input(shape=(5, 5))\n",
    "amore_layer1 = LSTM(128, return_sequences=True,activation='relu')(amore_input)\n",
    "amore_layer1 = Dropout(0.2)(amore_layer1)\n",
    "amore_layer2 = LSTM(256, activation='relu')(amore_layer1)\n",
    "amore_layer3 = Dense(1024, activation='relu')(amore_layer2)\n",
    "amore_layer4 = Dropout(0.2)(amore_layer3)\n",
    "amore_layer5 = Dense(512, activation='relu')(amore_layer4)\n",
    "amore_layer6 = Dense(128, activation='relu')(amore_layer5)\n",
    "amore_layer6 = Dense(32, activation='relu')(amore_layer6)\n",
    "amore_output = Dense(1)(amore_layer6)\n",
    "\n",
    "# 병합\n",
    "merge_layer1 = concatenate([samsung_output, amore_output])\n",
    "merge_layer2 = Dense(256, activation='relu')(merge_layer1)\n",
    "merge_layer3 = Dense(512, activation='relu')(merge_layer2)\n",
    "merge_layer4 = Dense(128, activation='relu')(merge_layer3)\n",
    "merge_layer5 = Dense(32, activation='relu')(merge_layer4)\n",
    "merge_output = Dense(1, activation='relu')(merge_layer5)\n",
    "\n",
    "model = Model(inputs=[samsung_input, amore_input], outputs=[merge_output])\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 컴파일, 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1024\n",
      "2/2 [==============================] - 4s 595ms/step - loss: 1415326728192.0000 - val_loss: 1384343273472.0000\n",
      "Epoch 2/1024\n",
      "2/2 [==============================] - 1s 237ms/step - loss: 1415326728192.0000 - val_loss: 1384343011328.0000\n",
      "Epoch 3/1024\n",
      "2/2 [==============================] - 1s 316ms/step - loss: 1415326334976.0000 - val_loss: 1384341438464.0000\n",
      "Epoch 4/1024\n",
      "2/2 [==============================] - 1s 228ms/step - loss: 1415324499968.0000 - val_loss: 1384335409152.0000\n",
      "Epoch 5/1024\n",
      "2/2 [==============================] - 1s 232ms/step - loss: 1415318339584.0000 - val_loss: 1384315748352.0000\n",
      "Epoch 6/1024\n",
      "2/2 [==============================] - 1s 280ms/step - loss: 1415295926272.0000 - val_loss: 1384250998784.0000\n",
      "Epoch 7/1024\n",
      "2/2 [==============================] - 1s 246ms/step - loss: 1415224229888.0000 - val_loss: 1384040497152.0000\n",
      "Epoch 8/1024\n",
      "2/2 [==============================] - 1s 252ms/step - loss: 1414993674240.0000 - val_loss: 1383333888000.0000\n",
      "Epoch 9/1024\n",
      "2/2 [==============================] - 1s 250ms/step - loss: 1414204227584.0000 - val_loss: 1381028986880.0000\n",
      "Epoch 10/1024\n",
      "2/2 [==============================] - 1s 242ms/step - loss: 1411667066880.0000 - val_loss: 1372754804736.0000\n",
      "Epoch 11/1024\n",
      "2/2 [==============================] - 1s 228ms/step - loss: 1402450608128.0000 - val_loss: 1343712919552.0000\n",
      "Epoch 12/1024\n",
      "2/2 [==============================] - 1s 251ms/step - loss: 1371151925248.0000 - val_loss: 1247153881088.0000\n",
      "Epoch 13/1024\n",
      "2/2 [==============================] - 1s 265ms/step - loss: 1263256338432.0000 - val_loss: 1031520321536.0000\n",
      "Epoch 14/1024\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 1016802508800.0000 - val_loss: 1425033265152.0000\n",
      "Epoch 15/1024\n",
      "2/2 [==============================] - 1s 254ms/step - loss: 1173651980288.0000 - val_loss: 1009065525248.0000\n",
      "Epoch 16/1024\n",
      "2/2 [==============================] - 1s 377ms/step - loss: 919957209088.0000 - val_loss: 971095867392.0000\n",
      "Epoch 17/1024\n",
      "2/2 [==============================] - 1s 132ms/step - loss: 948691271680.0000 - val_loss: 977187504128.0000\n",
      "Epoch 18/1024\n",
      "2/2 [==============================] - 1s 336ms/step - loss: 961548976128.0000 - val_loss: 927757172736.0000\n",
      "Epoch 19/1024\n",
      "2/2 [==============================] - 1s 133ms/step - loss: 890551205888.0000 - val_loss: 973462306816.0000\n",
      "Epoch 20/1024\n",
      "2/2 [==============================] - 1s 142ms/step - loss: 899454140416.0000 - val_loss: 970209427456.0000\n",
      "Epoch 21/1024\n",
      "2/2 [==============================] - 1s 290ms/step - loss: 890826588160.0000 - val_loss: 886635036672.0000\n",
      "Epoch 22/1024\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 851721912320.0000 - val_loss: 893125459968.0000\n",
      "Epoch 23/1024\n",
      "2/2 [==============================] - 1s 275ms/step - loss: 867420536832.0000 - val_loss: 877002948608.0000\n",
      "Epoch 24/1024\n",
      "2/2 [==============================] - 1s 229ms/step - loss: 845087440896.0000 - val_loss: 869373771776.0000\n",
      "Epoch 25/1024\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 828591505408.0000 - val_loss: 873656418304.0000\n",
      "Epoch 26/1024\n",
      "2/2 [==============================] - 1s 133ms/step - loss: 826665598976.0000 - val_loss: 882460131328.0000\n",
      "Epoch 27/1024\n",
      "2/2 [==============================] - 1s 113ms/step - loss: 833718910976.0000 - val_loss: 875299536896.0000\n",
      "Epoch 28/1024\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 824821940224.0000 - val_loss: 859292434432.0000\n",
      "Epoch 29/1024\n",
      "2/2 [==============================] - 1s 155ms/step - loss: 823021666304.0000 - val_loss: 860361916416.0000\n",
      "Epoch 30/1024\n",
      "2/2 [==============================] - 1s 135ms/step - loss: 827966881792.0000 - val_loss: 863451873280.0000\n",
      "Epoch 31/1024\n",
      "2/2 [==============================] - 1s 158ms/step - loss: 822011953152.0000 - val_loss: 878211366912.0000\n",
      "Epoch 32/1024\n",
      "2/2 [==============================] - 1s 126ms/step - loss: 831455887360.0000 - val_loss: 861207724032.0000\n",
      "Epoch 33/1024\n",
      "2/2 [==============================] - 1s 414ms/step - loss: 819914997760.0000 - val_loss: 859272511488.0000\n",
      "Epoch 34/1024\n",
      "2/2 [==============================] - 1s 295ms/step - loss: 820846002176.0000 - val_loss: 857472499712.0000\n",
      "Epoch 35/1024\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 819534954496.0000 - val_loss: 858676068352.0000\n",
      "Epoch 36/1024\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 819176931328.0000 - val_loss: 869831933952.0000\n",
      "Epoch 37/1024\n",
      "2/2 [==============================] - 1s 144ms/step - loss: 824962646016.0000 - val_loss: 871401193472.0000\n",
      "Epoch 38/1024\n",
      "2/2 [==============================] - 1s 149ms/step - loss: 825970982912.0000 - val_loss: 861330735104.0000\n",
      "Epoch 39/1024\n",
      "2/2 [==============================] - 1s 364ms/step - loss: 820402061312.0000 - val_loss: 856085037056.0000\n",
      "Epoch 40/1024\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 824016306176.0000 - val_loss: 856409636864.0000\n",
      "Epoch 41/1024\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 819931906048.0000 - val_loss: 862760861696.0000\n",
      "Epoch 42/1024\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 823080648704.0000 - val_loss: 864668745728.0000\n",
      "Epoch 43/1024\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 822741630976.0000 - val_loss: 857644466176.0000\n",
      "Epoch 44/1024\n",
      "2/2 [==============================] - 1s 217ms/step - loss: 820210499584.0000 - val_loss: 855835803648.0000\n",
      "Epoch 45/1024\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 822155476992.0000 - val_loss: 857558614016.0000\n",
      "Epoch 46/1024\n",
      "2/2 [==============================] - 0s 122ms/step - loss: 819661373440.0000 - val_loss: 868543692800.0000\n",
      "Epoch 47/1024\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 828049457152.0000 - val_loss: 866222014464.0000\n",
      "Epoch 48/1024\n",
      "2/2 [==============================] - 0s 124ms/step - loss: 821509685248.0000 - val_loss: 856049582080.0000\n",
      "Epoch 49/1024\n",
      "2/2 [==============================] - 1s 132ms/step - loss: 819688112128.0000 - val_loss: 859139276800.0000\n",
      "Epoch 50/1024\n",
      "2/2 [==============================] - 1s 140ms/step - loss: 832623673344.0000 - val_loss: 856153784320.0000\n",
      "Epoch 51/1024\n",
      "2/2 [==============================] - 1s 123ms/step - loss: 822651387904.0000 - val_loss: 874148462592.0000\n",
      "Epoch 52/1024\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 827079655424.0000 - val_loss: 861084909568.0000\n",
      "Epoch 53/1024\n",
      "2/2 [==============================] - 1s 110ms/step - loss: 822089875456.0000 - val_loss: 856310415360.0000\n",
      "Epoch 54/1024\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 823524130816.0000 - val_loss: 857120178176.0000\n",
      "Epoch 55/1024\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 819721076736.0000 - val_loss: 876895993856.0000\n",
      "Epoch 56/1024\n",
      "2/2 [==============================] - 1s 115ms/step - loss: 829655875584.0000 - val_loss: 876094095360.0000\n",
      "Epoch 57/1024\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 831573852160.0000 - val_loss: 858298777600.0000\n",
      "Epoch 58/1024\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 816457383936.0000 - val_loss: 856319131648.0000\n",
      "Epoch 59/1024\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 827286224896.0000 - val_loss: 857950060544.0000\n",
      "Epoch 60/1024\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 817651253248.0000 - val_loss: 912518217728.0000\n",
      "Epoch 61/1024\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 852934524928.0000 - val_loss: 902643712000.0000\n",
      "Epoch 62/1024\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 847013478400.0000 - val_loss: 856345935872.0000\n",
      "Epoch 63/1024\n",
      "2/2 [==============================] - 1s 127ms/step - loss: 820307165184.0000 - val_loss: 859470364672.0000\n",
      "Epoch 64/1024\n",
      "2/2 [==============================] - 1s 126ms/step - loss: 829466542080.0000 - val_loss: 856761499648.0000\n",
      "Epoch 65/1024\n",
      "2/2 [==============================] - 1s 123ms/step - loss: 825634127872.0000 - val_loss: 858770964480.0000\n",
      "Epoch 66/1024\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 820592640000.0000 - val_loss: 872286715904.0000\n",
      "Epoch 67/1024\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 826261307392.0000 - val_loss: 861564764160.0000\n",
      "Epoch 68/1024\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 820952891392.0000 - val_loss: 857137545216.0000\n",
      "Epoch 69/1024\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 828231516160.0000 - val_loss: 860739076096.0000\n",
      "Epoch 70/1024\n",
      "2/2 [==============================] - 1s 247ms/step - loss: 835497689088.0000 - val_loss: 855818305536.0000\n",
      "Epoch 71/1024\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 823975870464.0000 - val_loss: 862673108992.0000\n",
      "Epoch 72/1024\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 822868574208.0000 - val_loss: 870325420032.0000\n",
      "Epoch 73/1024\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 824001429504.0000 - val_loss: 863493947392.0000\n",
      "Epoch 74/1024\n",
      "2/2 [==============================] - 1s 112ms/step - loss: 822700081152.0000 - val_loss: 870035226624.0000\n",
      "Epoch 75/1024\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 826232143872.0000 - val_loss: 856592154624.0000\n",
      "Epoch 76/1024\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 819056279552.0000 - val_loss: 864045563904.0000\n",
      "Epoch 77/1024\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 840672346112.0000 - val_loss: 869131288576.0000\n",
      "Epoch 78/1024\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 845608779776.0000 - val_loss: 855874338816.0000\n",
      "Epoch 79/1024\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 825047646208.0000 - val_loss: 876608356352.0000\n",
      "Epoch 80/1024\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 834469822464.0000 - val_loss: 864434913280.0000\n",
      "Epoch 81/1024\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 823520985088.0000 - val_loss: 863252709376.0000\n",
      "Epoch 82/1024\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 840255012864.0000 - val_loss: 870980911104.0000\n",
      "Epoch 83/1024\n",
      "2/2 [==============================] - 1s 234ms/step - loss: 847564636160.0000 - val_loss: 855592534016.0000\n",
      "Epoch 84/1024\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 822407725056.0000 - val_loss: 880066232320.0000\n",
      "Epoch 85/1024\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 829978640384.0000 - val_loss: 861136617472.0000\n",
      "Epoch 86/1024\n",
      "2/2 [==============================] - 1s 177ms/step - loss: 819615367168.0000 - val_loss: 863121244160.0000\n",
      "Epoch 87/1024\n",
      "2/2 [==============================] - 1s 134ms/step - loss: 839060357120.0000 - val_loss: 866350661632.0000\n",
      "Epoch 88/1024\n",
      "2/2 [==============================] - 1s 150ms/step - loss: 843419418624.0000 - val_loss: 856265719808.0000\n",
      "Epoch 89/1024\n",
      "2/2 [==============================] - 1s 143ms/step - loss: 819261210624.0000 - val_loss: 873552150528.0000\n",
      "Epoch 90/1024\n",
      "2/2 [==============================] - 1s 140ms/step - loss: 826614808576.0000 - val_loss: 876065718272.0000\n",
      "Epoch 91/1024\n",
      "2/2 [==============================] - 1s 140ms/step - loss: 826917715968.0000 - val_loss: 858245824512.0000\n",
      "Epoch 92/1024\n",
      "2/2 [==============================] - 1s 147ms/step - loss: 821007548416.0000 - val_loss: 857625329664.0000\n",
      "Epoch 93/1024\n",
      "2/2 [==============================] - 1s 181ms/step - loss: 827430076416.0000 - val_loss: 857668976640.0000\n",
      "Epoch 94/1024\n",
      "2/2 [==============================] - 1s 143ms/step - loss: 826567032832.0000 - val_loss: 857001099264.0000\n",
      "Epoch 95/1024\n",
      "2/2 [==============================] - 1s 130ms/step - loss: 822649946112.0000 - val_loss: 872891154432.0000\n",
      "Epoch 96/1024\n",
      "2/2 [==============================] - 1s 235ms/step - loss: 826458963968.0000 - val_loss: 873715400704.0000\n",
      "Epoch 97/1024\n",
      "2/2 [==============================] - 1s 175ms/step - loss: 830384177152.0000 - val_loss: 856895520768.0000\n",
      "Epoch 98/1024\n",
      "2/2 [==============================] - 1s 632ms/step - loss: 818147360768.0000 - val_loss: 854920790016.0000\n",
      "Epoch 99/1024\n",
      "2/2 [==============================] - 1s 530ms/step - loss: 823204970496.0000 - val_loss: 854811934720.0000\n",
      "Epoch 100/1024\n",
      "2/2 [==============================] - 1s 310ms/step - loss: 823144677376.0000 - val_loss: 855239491584.0000\n",
      "Epoch 101/1024\n",
      "2/2 [==============================] - 1s 238ms/step - loss: 818657820672.0000 - val_loss: 866106146816.0000\n",
      "Epoch 102/1024\n",
      "2/2 [==============================] - 1s 319ms/step - loss: 822776561664.0000 - val_loss: 872079491072.0000\n",
      "Epoch 103/1024\n",
      "2/2 [==============================] - 1s 436ms/step - loss: 825124388864.0000 - val_loss: 854848307200.0000\n",
      "Epoch 104/1024\n",
      "2/2 [==============================] - 1s 341ms/step - loss: 826241515520.0000 - val_loss: 862877253632.0000\n",
      "Epoch 105/1024\n",
      "2/2 [==============================] - 1s 411ms/step - loss: 836890591232.0000 - val_loss: 854994780160.0000\n",
      "Epoch 106/1024\n",
      "2/2 [==============================] - 1s 285ms/step - loss: 819303088128.0000 - val_loss: 873790308352.0000\n",
      "Epoch 107/1024\n",
      "2/2 [==============================] - 1s 570ms/step - loss: 829607706624.0000 - val_loss: 864217792512.0000\n",
      "Epoch 108/1024\n",
      "2/2 [==============================] - 1s 418ms/step - loss: 819874365440.0000 - val_loss: 857341689856.0000\n",
      "Epoch 109/1024\n",
      "2/2 [==============================] - 1s 475ms/step - loss: 827184775168.0000 - val_loss: 868438114304.0000\n",
      "Epoch 110/1024\n",
      "2/2 [==============================] - 1s 307ms/step - loss: 845138821120.0000 - val_loss: 861127639040.0000\n",
      "Epoch 111/1024\n",
      "2/2 [==============================] - 1s 583ms/step - loss: 832697270272.0000 - val_loss: 861846700032.0000\n",
      "Epoch 112/1024\n",
      "2/2 [==============================] - 1s 362ms/step - loss: 817197613056.0000 - val_loss: 917899116544.0000\n",
      "Epoch 113/1024\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 860597059584.0000 - val_loss: 879983525888.0000\n",
      "Epoch 114/1024\n",
      "2/2 [==============================] - 1s 346ms/step - loss: 826173095936.0000 - val_loss: 857151373312.0000\n",
      "Epoch 115/1024\n",
      "2/2 [==============================] - 1s 177ms/step - loss: 827373387776.0000 - val_loss: 887241506816.0000\n",
      "Epoch 116/1024\n",
      "2/2 [==============================] - 1s 182ms/step - loss: 868721754112.0000 - val_loss: 894430543872.0000\n",
      "Epoch 117/1024\n",
      "2/2 [==============================] - 1s 203ms/step - loss: 877731315712.0000 - val_loss: 860143878144.0000\n",
      "Epoch 118/1024\n",
      "2/2 [==============================] - 1s 215ms/step - loss: 833169719296.0000 - val_loss: 878765277184.0000\n",
      "Epoch 119/1024\n",
      "2/2 [==============================] - 1s 173ms/step - loss: 835452272640.0000 - val_loss: 882578817024.0000\n",
      "Epoch 120/1024\n",
      "2/2 [==============================] - 1s 158ms/step - loss: 835982458880.0000 - val_loss: 855835869184.0000\n",
      "Epoch 121/1024\n",
      "2/2 [==============================] - 1s 154ms/step - loss: 819220709376.0000 - val_loss: 855810506752.0000\n",
      "Epoch 122/1024\n",
      "2/2 [==============================] - 1s 121ms/step - loss: 825274073088.0000 - val_loss: 855238115328.0000\n",
      "Epoch 123/1024\n",
      "2/2 [==============================] - 0s 122ms/step - loss: 823574265856.0000 - val_loss: 856319787008.0000\n",
      "Epoch 124/1024\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 820744290304.0000 - val_loss: 856067866624.0000\n",
      "Epoch 125/1024\n",
      "2/2 [==============================] - 1s 155ms/step - loss: 818635538432.0000 - val_loss: 857677168640.0000\n",
      "Epoch 126/1024\n",
      "2/2 [==============================] - 1s 137ms/step - loss: 819501465600.0000 - val_loss: 864522731520.0000\n",
      "Epoch 127/1024\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 820322566144.0000 - val_loss: 860968255488.0000\n",
      "Epoch 128/1024\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 820025425920.0000 - val_loss: 856416518144.0000\n",
      "Epoch 129/1024\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 821632237568.0000 - val_loss: 855838162944.0000\n",
      "Epoch 130/1024\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 822776496128.0000 - val_loss: 856062820352.0000\n",
      "Epoch 131/1024\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 821935800320.0000 - val_loss: 857129877504.0000\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mse', optimizer= 'adam')\n",
    "\n",
    "ES = EarlyStopping(monitor='val_loss', mode='auto', patience=32, restore_best_weights=True)\n",
    "MCP = ModelCheckpoint(monitor='val_loss', mode='auto', save_best_only=True,filepath = PATH + 'stock_ModelCheckPoint.hdf5') # 모델과 가중치 저장\n",
    "\n",
    "model.fit([samsung_x_train, amore_x_train], samsung_y_train , epochs=1024, batch_size=1024, validation_split=0.2, callbacks=[ES, MCP])\n",
    "\n",
    "model.save_weights(PATH + 'stock_weight.h5') # 가중치만 저장"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 평가, 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 80ms/step - loss: 812261048320.0000\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\nys\\anaconda3\\envs\\tf27\\lib\\site-packages\\keras\\engine\\training.py\", line 1621, in predict_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\nys\\anaconda3\\envs\\tf27\\lib\\site-packages\\keras\\engine\\training.py\", line 1611, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\nys\\anaconda3\\envs\\tf27\\lib\\site-packages\\keras\\engine\\training.py\", line 1604, in run_step  **\n        outputs = model.predict_step(data)\n    File \"c:\\Users\\nys\\anaconda3\\envs\\tf27\\lib\\site-packages\\keras\\engine\\training.py\", line 1572, in predict_step\n        return self(x, training=False)\n    File \"c:\\Users\\nys\\anaconda3\\envs\\tf27\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\nys\\anaconda3\\envs\\tf27\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 199, in assert_input_compatibility\n        raise ValueError(f'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\n\n    ValueError: Layer \"model_10\" expects 2 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 5, 1) dtype=int64>]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24444\\4286791140.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msamsung_x_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mamore_x_test\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msamsung_y_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1024\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpred_samsung_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamsung_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"loss(mse): :\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\nys\\anaconda3\\envs\\tf27\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\nys\\anaconda3\\envs\\tf27\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1127\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1128\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1129\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1130\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\nys\\anaconda3\\envs\\tf27\\lib\\site-packages\\keras\\engine\\training.py\", line 1621, in predict_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\nys\\anaconda3\\envs\\tf27\\lib\\site-packages\\keras\\engine\\training.py\", line 1611, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\nys\\anaconda3\\envs\\tf27\\lib\\site-packages\\keras\\engine\\training.py\", line 1604, in run_step  **\n        outputs = model.predict_step(data)\n    File \"c:\\Users\\nys\\anaconda3\\envs\\tf27\\lib\\site-packages\\keras\\engine\\training.py\", line 1572, in predict_step\n        return self(x, training=False)\n    File \"c:\\Users\\nys\\anaconda3\\envs\\tf27\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\nys\\anaconda3\\envs\\tf27\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 199, in assert_input_compatibility\n        raise ValueError(f'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\n\n    ValueError: Layer \"model_10\" expects 2 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 5, 1) dtype=int64>]\n"
     ]
    }
   ],
   "source": [
    "loss = model.evaluate([samsung_x_test, amore_x_test], samsung_y_test, batch_size=1024)\n",
    "pred_samsung_result = model.predict(samsung_y)\n",
    "\n",
    "print(\"loss(mse): :\", loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf27",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ee92469b7b40312ae4629e0ddda08362c800b4ec056b23028eec5e635e6d661f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
